{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95952f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import multiprocessing as mp\n",
    "from typing import Optional, List, Tuple\n",
    "\n",
    "import orjson\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_df(metric_file: str, extra_file: str, freq: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "\n",
    "    match = re.search(r\"bs-(\\d+)-outlen-(\\d+)\", metric_file)\n",
    "    bs = int(match.group(1))\n",
    "    outlen = int(match.group(2))\n",
    "\n",
    "    # assert f\"bs-{bs}-outlen-{outlen}\" in extra_file, f\"Mismatch in bs/outlen for {metric_file} and {extra_file}\"\n",
    "    print(f\"Loading {metric_file} and {extra_file} with bs={bs}, outlen={outlen}\")\n",
    "\n",
    "    try:\n",
    "        with open(metric_file, \"r\") as f:\n",
    "            content = f.readlines()[-1].replace(\"Infinity\", \"null\", 1)\n",
    "            metric_json = orjson.loads(content)\n",
    "        metrics = {\n",
    "            \"freq\": freq,\n",
    "            \"bs\": len(metric_json[\"input_lens\"]),\n",
    "            \"tokens\": metric_json[\"total_output_tokens\"],\n",
    "            \"duration\": metric_json[\"duration\"],\n",
    "            \"energy\": metric_json[\"old_energy\"],\n",
    "        }\n",
    "        df_metric = pd.DataFrame([metrics])\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {metric_file}: {e}\")\n",
    "        df_metric = pd.DataFrame(columns=[\"freq\", \"bs\", \"tokens\", \"duration\", \"energy\"])\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    extras = []\n",
    "\n",
    "    with open(extra_file, \"r\") as f:\n",
    "        extra_json = orjson.loads(f.read())\n",
    "\n",
    "    for request_id, extra_batch_infos in extra_json.items():\n",
    "        for token_idx, info in enumerate(extra_batch_infos):\n",
    "            if info[\"forward_mode\"] != 2:\n",
    "                continue\n",
    "            extras.append({\n",
    "                \"freq\": freq,\n",
    "                \"iteration_counter\": info[\"iteration_counter\"],\n",
    "                \"batch_size\": info[\"batch_size\"],\n",
    "                \"input_len\": 1,\n",
    "                \"output_len\": outlen,\n",
    "                \"tokens\": sum(info[\"num_total_computed_tokens_list\"]),\n",
    "                \"itl\": (info.get(\"itl\", 0) or 0) * 1000,  # ms\n",
    "                \"forward_time\": (info[\"timestamp_after_forward\"] - info[\"timestamp_before_forward\"]) * 1000,  # ms\n",
    "            })\n",
    "\n",
    "    df_extra = pd.DataFrame(extras)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return df_metric, df_extra\n",
    "\n",
    "def load_data(dir_path: str, freq: int, mode: str, mod: int = 1, mod_rem: int = 0) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    extra_files = glob.glob(os.path.join(dir_path, \"*-extra.json\"))\n",
    "    extra_files.sort()\n",
    "    metric_files = [f.replace(\"-extra\", \"\") for f in extra_files]\n",
    "\n",
    "    assert mode in [\"save\", \"load\"], \"Mode must be either 'save' or 'load'.\"\n",
    "\n",
    "    metric_dfs = []\n",
    "    extra_dfs = []\n",
    "\n",
    "    for idx, (metric_file, extra_file) in enumerate(zip(metric_files, extra_files)):\n",
    "\n",
    "        if idx % mod != mod_rem:\n",
    "            continue\n",
    "\n",
    "        df_metric_file = metric_file.replace(\".json\", \".csv\")\n",
    "        df_extra_file = extra_file.replace(\".json\", \".csv\")\n",
    "        if mode == \"load\":\n",
    "            print(f\"Loading {df_metric_file} and {df_extra_file}\")\n",
    "            if not os.path.exists(df_metric_file) or not os.path.exists(df_extra_file):\n",
    "                print(f\"Files {df_metric_file} or {df_extra_file} do not exist.\")\n",
    "                continue\n",
    "            df_metric = pd.read_csv(df_metric_file)\n",
    "            df_extra = pd.read_csv(df_extra_file)\n",
    "        elif mode == \"save\":\n",
    "            metric_file = metric_file + \"-detail\"\n",
    "            df_metric, df_extra = convert_to_df(metric_file, extra_file, freq)\n",
    "            df_metric.to_csv(df_metric_file, index=False)\n",
    "            df_extra.to_csv(df_extra_file, index=False)\n",
    "        metric_dfs.append(df_metric)\n",
    "        extra_dfs.append(df_extra)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    df_metric = pd.concat(metric_dfs, ignore_index=True)\n",
    "    df_extra = pd.concat(extra_dfs, ignore_index=True)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    print(f\"Loaded {len(metric_dfs)} metric files and {len(extra_dfs)} extra files for freq={freq}, mode={mode}, mod={mod}, mod_rem={mod_rem}.\")\n",
    "\n",
    "    return df_metric, df_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902768fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metric_list = []\n",
    "df_extra_list = []\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "args = []\n",
    "\n",
    "mod = 10\n",
    "\n",
    "for freq in [1005, 1095, 1200, 1305, 1410]:\n",
    "    for mod_rem in range(mod):\n",
    "        args.append((str(freq), freq, \"save\", mod, mod_rem))\n",
    "        # args.append((str(freq), freq, \"load\", mod, mod_rem))\n",
    "\n",
    "results = pool.starmap(load_data, args)\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "for df_metric, df_extra in results:\n",
    "    df_metric_list.append(df_metric)\n",
    "    df_extra_list.append(df_extra)\n",
    "\n",
    "print(f\"Loaded {len(df_metric_list)} metric files and {len(df_extra_list)} extra files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa661a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dask = pd.concat(df_extra_list, ignore_index=True)\n",
    "\n",
    "print(df_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4b11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dask = pd.concat(df_extra_list, ignore_index=True)\n",
    "df_dask.sort_values(by=[\"freq\", \"batch_size\", \"tokens\", \"itl\", \"forward_time\"], inplace=True)\n",
    "\n",
    "df = df_dask\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abf285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a24a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df_itl = df[(df[\"itl\"] > 3) & (df[\"itl\"] < 300)]  # adjust it\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "df_itl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "\n",
    "steps_end = [4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 256, 384, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048]\n",
    "# steps_end = [4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 256, 384, 512, 640, 768, 896, 1024]\n",
    "steps_beg = [1] + [v + 1 for v in steps_end[:-1]]\n",
    "\n",
    "freq_color_map = {\n",
    "    1005: \"blue\",\n",
    "    1095: \"green\",\n",
    "    1200: \"purple\",\n",
    "    1305: \"cyan\",\n",
    "    1410: \"orange\",\n",
    "}\n",
    "\n",
    "def draw(df: pd.DataFrame, freq_list: Optional[List[int]] = None, save_csv: bool = False):\n",
    "\n",
    "    xs_total = df[\"batch_size\"].to_numpy()\n",
    "    ys_total = df[\"tokens\"].to_numpy()\n",
    "    # zs_total = df[\"forward_time\"].to_numpy()\n",
    "    zs_total = df[\"itl\"].to_numpy()\n",
    "\n",
    "    table_items = []\n",
    "\n",
    "    # figures\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    freq_list = freq_list if freq_list else df[\"freq\"].unique().tolist()\n",
    "\n",
    "    for freq in freq_list:\n",
    "\n",
    "        print(f\"Processing frequency: {freq}\")\n",
    "\n",
    "        sel = df[\"freq\"] == freq\n",
    "        xs_freq = xs_total[sel]\n",
    "        ys_freq = ys_total[sel]\n",
    "        zs_freq = zs_total[sel]\n",
    "        color = freq_color_map.get(freq, \"gray\")\n",
    "\n",
    "        label_added = False\n",
    "\n",
    "        for beg, end in zip(steps_beg, steps_end):\n",
    "            sel = (xs_freq >= beg) & (xs_freq <= end)\n",
    "            if np.sum(sel) == 0:\n",
    "                continue\n",
    "            xs_sel = xs_freq[sel]\n",
    "            ys_sel = ys_freq[sel]\n",
    "            zs_sel = zs_freq[sel]\n",
    "            print(f\"BS {beg}-{end}: {len(xs_sel)} points\")\n",
    "\n",
    "            if len(xs_sel) < 2:\n",
    "                print(f\"Skipping batch size range {beg}-{end} due to insufficient data points.\")\n",
    "                continue\n",
    "\n",
    "            regressor = RANSACRegressor(\n",
    "                LinearRegression(\n",
    "                    positive=True,\n",
    "                ),\n",
    "                max_trials=10000,\n",
    "                loss=\"squared_error\",\n",
    "                random_state=1,\n",
    "            )\n",
    "\n",
    "            xy_sel = np.vstack((xs_sel, ys_sel)).T\n",
    "            regressor.fit(xy_sel, zs_sel)\n",
    "            coef_bs = regressor.estimator_.coef_[0]\n",
    "            coef_tokens = regressor.estimator_.coef_[1]\n",
    "            intercept = regressor.estimator_.intercept_\n",
    "            r_2 = r2_score(zs_sel, regressor.predict(xy_sel))\n",
    "            print(f\"RANSAC Regression Coefficients: {coef_bs:.10f} (#reqs), {coef_tokens:.10f} (#computed tokens), Intercept: {intercept:.10f}, R^2: {r_2:.10f}\")\n",
    "\n",
    "            table_items.append({\n",
    "                \"freq\": freq,\n",
    "                \"bs_start\": beg,\n",
    "                \"bs_end\": end,\n",
    "                \"coef_bs\": coef_bs,\n",
    "                \"coef_tokens\": coef_tokens,\n",
    "                \"coef_intercept\": intercept,\n",
    "                \"r_2\": r_2,\n",
    "            })\n",
    "\n",
    "            x_range = np.linspace(beg, end, 100)\n",
    "            y_range = np.linspace(ys_sel.min(), ys_sel.max(), 100)\n",
    "            X, Y = np.meshgrid(x_range, y_range)\n",
    "            Z = regressor.predict(np.vstack((X.ravel(), Y.ravel())).T).reshape(X.shape)\n",
    "\n",
    "            if freq in [1005, 1410, 1305, 1200, 1095]:\n",
    "\n",
    "                N = 100\n",
    "                if len(xs_sel) > N:\n",
    "                    sel_draw = np.random.choice(len(xs_sel), N, replace=False)\n",
    "                    xs_draw = xs_sel[sel_draw]\n",
    "                    ys_draw = ys_sel[sel_draw]\n",
    "                    zs_draw = zs_sel[sel_draw]\n",
    "                    ax.scatter(xs_draw, ys_draw, zs_draw, c=color, s=50, alpha=0.5)\n",
    "\n",
    "                if not label_added:\n",
    "                    ax.plot_surface(X, Y, Z, color=color, alpha=0.5, rstride=100, cstride=100, label=f\"f = {freq} MHz\")\n",
    "                    label_added = True\n",
    "                else:\n",
    "                    ax.plot_surface(X, Y, Z, color=color, alpha=0.5, rstride=100, cstride=100)\n",
    "\n",
    "    ax.set_xlim(0)\n",
    "    ax.set_ylim(0)\n",
    "    ax.view_init(elev=35, azim=-135)\n",
    "    ax.set_xlabel(\"#Reqs\")\n",
    "    ax.set_ylabel(\"#Computed Tokens\", labelpad=10)\n",
    "    ax.set_zlabel(\"ITL (ms)\")\n",
    "    fig.legend(fontsize=11, loc='upper left', bbox_to_anchor=(0.1, 0.85))\n",
    "    # ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    # ax.set_yticks(np.arange(ax.get_yticks().min(), ax.get_yticks().max() + 1, ))\n",
    "    # ax.set_title(\"ITL vs #Reqs and #Computed Tokens\")\n",
    "\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    from matplotlib.transforms import Bbox\n",
    "    custom_bbox = Bbox.from_bounds(x0=-0.2, y0=0, width=5.95, height=5.55)\n",
    "    # fig.savefig(f\"itl-prediction.pdf\", dpi=300, bbox_inches=custom_bbox)\n",
    "    plt.show()\n",
    "\n",
    "    if save_csv:\n",
    "        table_df = pd.DataFrame(table_items)\n",
    "        table_df.sort_values(by=[\"freq\", \"bs_start\", \"bs_end\"], inplace=True, ignore_index=True)\n",
    "        csv_file = f\"latency-decode.csv\"\n",
    "        print(f\"Saving data to {csv_file}\")\n",
    "        table_df.to_csv(csv_file, index=False)\n",
    "\n",
    "draw(df_itl, save_csv=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voltanallm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
